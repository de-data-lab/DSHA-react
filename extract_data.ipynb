{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99936540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d45257",
   "metadata": {},
   "source": [
    "Process the raw excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b121bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the excel sheet and skip blank rows\n",
    "raw_excel = pd.read_excel(\"data/DSHA LIHTC List_MAPPING.xlsx\", engine='openpyxl', skiprows=[2,3], skipfooter=4, dtype=str)\n",
    "# Add additional column information from the first row\n",
    "raw_excel.columns = (raw_excel.columns.astype(str) + \" \" + raw_excel.head(1).fillna(\"\").astype(str)).iloc[0].str.strip().values\n",
    "raw_excel.rename(columns={\"ALLOCATION .1 DATE\": \"ALLOCATION DATE\", \"ALLOCATION  AMOUNT\": \"ALLOCATION AMOUNT\", \"Type of Property*\": \"Type of Property\"}, inplace=True)\n",
    "raw_excel.drop(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade04c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and label the rows about tax year\n",
    "raw_excel[\"is tax\"] = raw_excel[\"PROJECT NAME & ADDRESS\"].str.contains(\"TAX CREDIT ALLOCATIONS\")\n",
    "\n",
    "# Function that maps the boolean column \"is tax\", which is true when a row contains tax year information, to an integer equal to the tax year\n",
    "def assign_to_year(x, i):\n",
    "    # if the row is a tax year, increment i\n",
    "    if x:\n",
    "        i[0] = i[0] + 1\n",
    "    # return an integer equal to the tax year\n",
    "    return i[0] + 2016\n",
    "\n",
    "# add a column for the tax year\n",
    "index = [-1]\n",
    "raw_excel[\"Tax Allocation Year\"] = raw_excel[\"is tax\"].apply(assign_to_year, args=[index])\n",
    "\n",
    "# drop rows of tax year information and reformat\n",
    "raw_excel = raw_excel.loc[~raw_excel[\"is tax\"]].drop(columns=\"is tax\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8069ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column that labels the primary line for an entry\n",
    "raw_excel[\"primary\"] = ~raw_excel[\"County\"].isna()\n",
    "\n",
    "# Function that maps each the boolean column \"primary\", which is true when a row contains the primary info from the dataset, to an integer that functions as an index for primary entries\n",
    "def assign_to_year(x, i):\n",
    "    # if the row is primary, increment i\n",
    "    if x:\n",
    "        i[0] = i[0] + 1\n",
    "    # return an index for the primary entries\n",
    "    return i[0]\n",
    "\n",
    "# add an index column for the primary entries\n",
    "index = [-1]\n",
    "raw_excel[\"primary\"] = raw_excel[\"primary\"].apply(assign_to_year, args=[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc2d2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix 'ALLOCATION AMOUNT', 'ALLOCATION DATE' swap\n",
    "flipped_years = [2018, 2019, 2020, 2021, 2022]\n",
    "tmp = raw_excel.loc[raw_excel[\"Tax Allocation Year\"].isin(flipped_years)]['ALLOCATION AMOUNT'].copy()\n",
    "tmp2 = raw_excel.loc[raw_excel[\"Tax Allocation Year\"].isin(flipped_years)]['ALLOCATION DATE'].copy()\n",
    "raw_excel.loc[raw_excel[\"Tax Allocation Year\"].isin(flipped_years), 'ALLOCATION AMOUNT'] = tmp2.values\n",
    "raw_excel.loc[raw_excel[\"Tax Allocation Year\"].isin(flipped_years), 'ALLOCATION DATE'] = tmp.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de59457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate dataframes for each row in a data entry\n",
    "grouped_data = raw_excel.groupby(\"primary\")\n",
    "raw_data1 = grouped_data.nth(0)\n",
    "raw_data2 = grouped_data.nth(1).drop(columns=\"Tax Allocation Year\")\n",
    "raw_data3 = grouped_data.nth(2).drop(columns=\"Tax Allocation Year\")\n",
    "raw_data4 = grouped_data.nth(3).drop(columns=\"Tax Allocation Year\")\n",
    "raw_data5 = grouped_data.nth(4).drop(columns=\"Tax Allocation Year\")\n",
    "\n",
    "# Modify the column names for each dataframe to prepare for joining\n",
    "raw_data2.columns = raw_data2.columns + \" 2\"\n",
    "raw_data3.columns = raw_data3.columns + \" 3\"\n",
    "raw_data4.columns = raw_data4.columns + \" 4\"\n",
    "raw_data5.columns = raw_data5.columns + \" 5\"\n",
    "\n",
    "# Join the dataframes by index and remove unused columns\n",
    "flattened_data = raw_data1.join(raw_data2, how=\"left\").join(raw_data3, how=\"left\").join(raw_data4, how=\"left\").join(raw_data5, how=\"left\").dropna(axis=1, how='all').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ff1246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates back to their orginial format\n",
    "flattened_data[\"Placed in Service Date\"] = pd.to_datetime(flattened_data[\"Placed in Service Date\"], errors='coerce').dt.strftime('%m/%d/%Y')\n",
    "flattened_data[\"ALLOCATION DATE\"] = pd.to_datetime(flattened_data[\"ALLOCATION DATE\"], errors='coerce').dt.strftime('%m/%d/%Y')\n",
    "flattened_data[\"Tax Credit Compliance Date\"] = pd.to_datetime(flattened_data[\"Tax Credit Compliance Date\"], errors='coerce').dt.strftime('%m/%d/%Y')\n",
    "flattened_data[\"Extended Use Period\"] = pd.to_datetime(flattened_data[\"Extended Use Period\"], errors='coerce').dt.strftime('%m/%d/%Y')\n",
    "flattened_data[\"Placed in Service Date 2\"] = pd.to_datetime(flattened_data[\"Placed in Service Date 2\"], errors='coerce').dt.strftime('%m/%d/%Y')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82d1a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine address fields\n",
    "address_columns = [\"PROJECT NAME & ADDRESS\", \"PROJECT NAME & ADDRESS 2\", \"PROJECT NAME & ADDRESS 3\", \"PROJECT NAME & ADDRESS 4\", \"PROJECT NAME & ADDRESS 5\"]\n",
    "\n",
    "# Extracts addresses from projects\n",
    "def extract_address(x):\n",
    "    # Project 27 has three full addresses, so we use the last one listed\n",
    "    if x.name == 27:\n",
    "        addr = x[address_columns].dropna().values[-1]\n",
    "        return addr\n",
    "    # The last two lines of the address field contain the address split between two lines, except for project 27\n",
    "    else:\n",
    "        addr = x[address_columns].dropna().values[-2:]\n",
    "        return addr[0] + \", \" + addr[1]\n",
    "\n",
    "# Extract an address for each project\n",
    "flattened_data[\"address\"] = flattened_data.apply(extract_address, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd04535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert years to string\n",
    "flattened_data[\"Tax Allocation Year\"] = flattened_data[\"Tax Allocation Year\"].astype(str)\n",
    "\n",
    "# Print the data to a csv\n",
    "flattened_data.to_csv(\"data/processed_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756363da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the addresses to a seperate list\n",
    "flattened_data[\"address\"].to_csv(\"data/DSHA_addresses.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9463324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613a7893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ba495db",
   "metadata": {},
   "source": [
    "At this point we transfer the address csv over to the geocoder to get the latitude and longitude of each project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a62066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file of geolocated addresses\n",
    "geolocations = pd.read_csv(\"data/counts_per_tract.csv\").drop_duplicates(\"input addresses\")\n",
    "# Join the geolocations to the flattened dataframe\n",
    "geolocated_data = flattened_data.merge(geolocations, left_on=\"address\", right_on=\"input addresses\", how=\"inner\")\n",
    "# Remove lat,lot from unsuccessfully (not in the u.s.) geolocated address\n",
    "geolocated_data.loc[geolocated_data[\"census tract\"] == \"Unable To Geolocate The Address\", \"lot\"] = np.nan\n",
    "geolocated_data.loc[geolocated_data[\"census tract\"] == \"Unable To Geolocate The Address\", \"lat\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fc3e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lat,lot to Shapely points\n",
    "geolocated_data = gpd.GeoDataFrame(geolocated_data, geometry=gpd.points_from_xy(geolocated_data['lat'], geolocated_data['lot'], crs=\"EPSG:4326\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415df177",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Visualize points on a map\n",
    "\n",
    "# initialize the map and store it in a folium map object\n",
    "us_map = folium.Map(location=[39.74503, -75.57203], zoom_start=14, tiles=None)\n",
    "\n",
    "# Add background tiles\n",
    "folium.TileLayer('CartoDB positron',name=\"Light Map\",control=False).add_to(us_map)\n",
    "\n",
    "\n",
    "# Add markers for each school\n",
    "points=folium.features.GeoJson(\n",
    "        geolocated_data.loc[geolocated_data[\"census tract\"] != \"Unable To Geolocate The Address\"], # Full geopandas data\n",
    "        control=False,\n",
    "        marker = folium.CircleMarker(radius = 5, # Radius in metres\n",
    "                           weight = 0, #outline weight\n",
    "                           fill_color = '#d95f02', \n",
    "                           fill_opacity = 1)\n",
    "        )\n",
    "\n",
    "points.add_to(us_map)\n",
    "us_map\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5c0202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract shape files for senate districts\n",
    "senate_districts2020 = gpd.read_file(\"data/2020Senate_Districts_Trimmed.geojson\")\n",
    "senate_districts2010 = gpd.read_file(\"data/2010Senate_Districts_Trimmed.geojson\")\n",
    "\n",
    "# Gets the senate district containing a point\n",
    "def get_district(x):\n",
    "    # Return a blank when an address could not be geolocated\n",
    "    if x[\"census tract\"] == \"Unable To Geolocate The Address\":\n",
    "        return \"\"\n",
    "    # Return the senate district containing the point otherwise\n",
    "    else:\n",
    "        if x[\"Tax Allocation Year\"] < \"2022\":\n",
    "            return senate_districts2010.loc[x[\"geometry\"].within(senate_districts2010[\"geometry\"])][\"SLDUST\"].astype(int).astype(str).values[0]\n",
    "        else:\n",
    "            return senate_districts2020.loc[x[\"geometry\"].within(senate_districts2020[\"geometry\"])][\"SLDUST\"].astype(int).astype(str).values[0]\n",
    "# Add a column for senate district\n",
    "geolocated_data[\"Senate District\"] = geolocated_data.apply(get_district, axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e44ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4584819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d419f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add funding source column\n",
    "geolocated_data[\"Funding Source\"] = \"LIHTC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba3eb19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b1322c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245cc71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the dataset with senate districts attached to a csv\n",
    "geolocated_data.drop(columns=[\"input addresses\", \"census tract\", \"lot\", \"lat\"]).to_file(\"data/DSHA_districted.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d2f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocated_data.drop(columns=[\"input addresses\", \"census tract\", \"lot\", \"lat\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aaa392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3089510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of Tax Credit Units in each district for each year and add them to the aggregated dataframe\n",
    "geolocated_data['# of Tax Credit Units'] = geolocated_data['# of Tax Credit Units'].astype(int)\n",
    "aggregated_data = geolocated_data.groupby([\"Senate District\", \"Tax Allocation Year\"]).sum()[\"# of Tax Credit Units\"].reset_index()\n",
    "aggregated_data.to_csv(\"data/Tax_Credit_Units_per_Senate_District.csv\", index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdab10b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the Allocation Amount in each district for each year and add them to the aggregated dataframe\n",
    "data_noTBD = geolocated_data.loc[geolocated_data['ALLOCATION AMOUNT'] != \"TBD\"]\n",
    "data_noTBD[\"ALLOCATION AMOUNT\"] = data_noTBD['ALLOCATION AMOUNT'].astype(int)\n",
    "aggregated_data = aggregated_data.merge(data_noTBD.groupby([\"Senate District\", \"Tax Allocation Year\"]).sum()[\"ALLOCATION AMOUNT\"].reset_index(), how=\"outer\", on=[\"Senate District\", \"Tax Allocation Year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55e685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull senate district population for each year in the dataset\n",
    "population_data = []\n",
    "# Define request parameters\n",
    "\n",
    "years = aggregated_data[\"Tax Allocation Year\"].unique() # Years of interest\n",
    "datasource = 'acs' # Survey name\n",
    "subsource = 'acs5' # Subsurvey name\n",
    "GET = 'B01001_001E' # Variables to query\n",
    "FOR = 'state%20legislative%20district%20(upper%20chamber):*' # for predicate\n",
    "IN = 'state:10'\n",
    "\n",
    "# Filepath to your Census API key\n",
    "keyfile = 'CensusAPIKey.txt'\n",
    "\n",
    "# Iterate over each non-nan year\n",
    "for year in years:\n",
    "    if year:\n",
    "        # the acs2022 is not yet available, so use 2021 data\n",
    "        if year == \"2022\":\n",
    "            # Formatted API call\n",
    "            data_url = f'https://api.census.gov/data/2021/{datasource}/{subsource}?get={GET}&for={FOR}&in={IN}'  \n",
    "        # Otherwise, use the population data for the year\n",
    "        else:\n",
    "            # Formatted API call\n",
    "            data_url = f'https://api.census.gov/data/{year}/{datasource}/{subsource}?get={GET}&for={FOR}&in={IN}'\n",
    "\n",
    "        # Read Census key into 'api_key'\n",
    "        with open(keyfile) as key:\n",
    "            api_key = key.read().strip()\n",
    "\n",
    "        # Add key to url\n",
    "        data_url = f'{data_url}&key={api_key}'\n",
    "\n",
    "        # Request data and convert from json\n",
    "        data = requests.get(data_url).json()\n",
    "        # First entry in list is a list of variable names\n",
    "        data = pd.DataFrame(data[1:], columns = data[0])\n",
    "        # Add the year as a column\n",
    "        data[\"year\"] = year\n",
    "        # Convert district number to an integer\n",
    "        data[\"state legislative district (upper chamber)\"] = data[\"state legislative district (upper chamber)\"].astype(int).astype(str)\n",
    "        # Drop the state column\n",
    "        data.drop(columns=\"state\", inplace=True)\n",
    "        # Rename the population variable\n",
    "        data.rename(columns={\"B01001_001E\": \"Population\"}, inplace=True)\n",
    "        population_data.append(data)\n",
    "\n",
    "population_data = pd.concat(population_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bf01ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add derived statistics, population data, senator name, and funding source to the aggregated dataframe\n",
    "aggregated_data = aggregated_data.merge(gpd.read_file(\"data/aggregated_senate_new.json\")[[\"name\", \"district\"]], how=\"outer\", left_on=\"Senate District\", right_on=\"district\").drop(columns=\"Senate District\")\n",
    "aggregated_data = aggregated_data.merge(population_data, left_on=[\"district\", \"Tax Allocation Year\"], right_on=[\"state legislative district (upper chamber)\", \"year\"], how=\"left\").drop(columns=[\"state legislative district (upper chamber)\", \"year\"])\n",
    "# Filter out \"S.\" from the beginning of senator names\n",
    "aggregated_data[\"name\"] = aggregated_data[\"name\"].str.removeprefix(\"S. \")\n",
    "# Add funding source\n",
    "aggregated_data[\"Funding Source\"] = \"LIHTC\"\n",
    "\n",
    "# Calculate derived statistics\n",
    "aggregated_data[\"Average Allocation per 100 Persons\"] = aggregated_data[\"ALLOCATION AMOUNT\"] * 100 / aggregated_data[\"Population\"].astype(float)\n",
    "aggregated_data[\"Average Population per Tax Credit Unit\"] = aggregated_data[\"Population\"].astype(float) / aggregated_data[\"# of Tax Credit Units\"]\n",
    "aggregated_data[\"Average Allocation per Tax Credit Unit\"] = aggregated_data[\"ALLOCATION AMOUNT\"].astype(float) / aggregated_data[\"# of Tax Credit Units\"]\n",
    "\n",
    "# Convert adjusted population to int. Assume anywhere with missing population numbers has a population of 0\n",
    "aggregated_data[\"Population\"] = aggregated_data[\"Population\"].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249bc2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the wide form data into long form data, grouping by district, senator name, funding source, and year\n",
    "long_data = pd.melt(aggregated_data, id_vars=[\"district\", \"name\", \"Funding Source\", \"Tax Allocation Year\"], value_vars=[\"Population\", \"# of Tax Credit Units\", \"ALLOCATION AMOUNT\", \"Average Allocation per 100 Persons\", \"Average Population per Tax Credit Unit\", \"Average Allocation per Tax Credit Unit\"])\n",
    "\n",
    "# Remove nan district from long form data\n",
    "long_data = long_data.loc[~long_data[\"district\"].isna()]\n",
    "\n",
    "# Calculate the averages of each variable across all districts in each year\n",
    "yearly_averages = long_data.loc[~long_data[\"Tax Allocation Year\"].isna()].groupby([\"variable\", \"Tax Allocation Year\"]).mean(numeric_only=True).reset_index()\n",
    "yearly_averages[\"Funding Source\"] = \"LIHTC\"\n",
    "yearly_averages[\"name\"] = np.nan\n",
    "yearly_averages[\"district\"] = \"District Average\"\n",
    "\n",
    "# Add the averages to the long form data\n",
    "long_data = pd.concat([long_data, yearly_averages])\n",
    "# Fill missing values with 0 for processing\n",
    "long_data.fillna(0).to_csv(\"data/long_tax_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be323ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split district data into 2022 and non-2022 sections to isolate the 2020 senate district cycle\n",
    "aggregated_data2010 = aggregated_data.loc[aggregated_data[\"Tax Allocation Year\"] < \"2022\"]\n",
    "aggregated_data2020 = aggregated_data.loc[aggregated_data[\"Tax Allocation Year\"] >= \"2022\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df336dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current senator names for each district\n",
    "extras = gpd.read_file(\"data/aggregated_senate_new.json\")[[\"name\", \"district\"]]\n",
    "extras[\"district\"] = extras[\"district\"].astype(int).astype(str)\n",
    "\n",
    "# Read trimmed senate distrcit shapes\n",
    "trim2020 = gpd.read_file(\"data/2020Senate_Districts_Trimmed.geojson\", driver=\"GeoJSON\")\n",
    "trim2020[\"district\"] = trim2020[\"SLDUST\"].astype(int).astype(str)\n",
    "trim2020 = trim2020[[\"district\", \"geometry\"]]\n",
    "\n",
    "# Add derived statistics, population data, senator name, and funding source to the trimmed shapefiles\n",
    "trim2020 = trim2020.merge(extras, how=\"left\", on=\"district\")\n",
    "# Filter out \"S.\" from the beginning of senator names\n",
    "trim2020[\"name\"] = trim2020[\"name\"].str.removeprefix(\"S. \")\n",
    "# Add population data and duplicate across years\n",
    "trim2020 = trim2020.merge(population_data, left_on=\"district\", right_on=\"state legislative district (upper chamber)\", how=\"outer\").drop(columns=\"state legislative district (upper chamber)\")\n",
    "trim2020 = trim2020.loc[trim2020[\"year\"].isin([\"2022\"])]\n",
    "# Add funding source\n",
    "trim2020[\"Funding Source\"] = \"LIHTC\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Read trimmed senate distrcit shapes\n",
    "trim2010 = gpd.read_file(\"data/2010Senate_Districts_Trimmed.geojson\", driver=\"GeoJSON\")\n",
    "trim2010[\"district\"] = trim2010[\"SLDUST\"].astype(int).astype(str)\n",
    "trim2010 = trim2010[[\"district\", \"geometry\"]]\n",
    "\n",
    "# Add derived statistics, population data, senator name, and funding source to the trimmed shapefiles\n",
    "trim2010 = trim2010.merge(extras, how=\"left\", on=\"district\")\n",
    "# Filter out \"S.\" from the beginning of senator names\n",
    "trim2010[\"name\"] = trim2010[\"name\"].str.removeprefix(\"S. \")\n",
    "# Add population data and duplicate across years\n",
    "trim2010 = trim2010.merge(population_data, left_on=\"district\", right_on=\"state legislative district (upper chamber)\", how=\"outer\").drop(columns=\"state legislative district (upper chamber)\")\n",
    "trim2010 = trim2010.loc[trim2010[\"year\"].isin([\"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\"])]\n",
    "# Add funding source\n",
    "trim2010[\"Funding Source\"] = \"LIHTC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8ad84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop district information from aggregated data\n",
    "aggregated_data2010 = aggregated_data2010.drop(columns=[\"Population\", \"Funding Source\", \"name\"])\n",
    "\n",
    "# Attach senate districts to wide form aggregated data\n",
    "aggregated_data2010 = aggregated_data2010.merge(trim2010, left_on=[\"district\", \"Tax Allocation Year\"], right_on=[\"district\", \"year\"], how=\"right\").drop(columns=\"Tax Allocation Year\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Drop district information from aggregated data\n",
    "aggregated_data2020 = aggregated_data2020.drop(columns=[\"Population\", \"Funding Source\", \"name\"])\n",
    "\n",
    "# Attach senate districts to wide form aggregated data\n",
    "aggregated_data2020 = aggregated_data2020.merge(trim2020, left_on=[\"district\", \"Tax Allocation Year\"], right_on=[\"district\", \"year\"], how=\"right\").drop(columns=\"Tax Allocation Year\")                                                                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72d2554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-attach data for summing\n",
    "aggregated_data = pd.concat([aggregated_data2010, aggregated_data2020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981ea42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the sum of all allocations in a district\n",
    "sums = aggregated_data.groupby(\"district\").sum(numeric_only=True).reset_index()\n",
    "# Add name, adjusted population, funding source, and geometry back in\n",
    "sums = aggregated_data2020[[\"district\", \"name\", \"Population\", \"Funding Source\", \"geometry\"]].drop_duplicates(\"district\").merge(sums, on=\"district\", how=\"right\")\n",
    "# Label tax allocation year as sum over time\n",
    "sums[\"year\"] = \"Sum over All Time\"\n",
    "# Add sums over time to aggregated data\n",
    "aggregated_data2020 = pd.concat([aggregated_data2020, sums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07537d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the wide form data for valid districts to a geojson\n",
    "gpd.GeoDataFrame(aggregated_data2020.loc[~aggregated_data2020[\"district\"].isna()]).to_file(\"data/aggregated_with_geo2020.geojson\", driver=\"GeoJSON\")\n",
    "# Print the wide form data without geoometry to a csv\n",
    "aggregated_data2020.drop(columns=\"geometry\").to_csv(\"data/aggregated_data_with_na2020.csv\", index=False)\n",
    "\n",
    "\n",
    "# Print the wide form data for valid districts to a geojson\n",
    "gpd.GeoDataFrame(aggregated_data2010.loc[~aggregated_data2010[\"district\"].isna()]).to_file(\"data/aggregated_with_geo2010.geojson\", driver=\"GeoJSON\")\n",
    "# Print the wide form data without geoometry to a csv\n",
    "aggregated_data2010.drop(columns=\"geometry\").to_csv(\"data/aggregated_data_with_na2010.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093c9f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "635d50c4",
   "metadata": {},
   "source": [
    "Figure out how senate districts overlap with senate districts\n",
    "\n",
    "\n",
    "NOTE: PyPDF2 needs to be added to the environment and imported to run this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4226d6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download census block groups\n",
    "blocks = requests.get(\"https://www2.census.gov/geo/tiger/GENZ2022/shp/cb_2022_10_bg_500k.zip\")\n",
    "blocks = gpd.read_file(BytesIO(blocks.content))\n",
    "blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ad77f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "\n",
    "# creating a pdf file object\n",
    "with open('data/CensusBlockBreakdownbySenateDistrict.pdf', 'rb') as pdfFileObj:\n",
    "    # creating a pdf reader object\n",
    "    pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "\n",
    "    # printing number of pages in pdf file\n",
    "    print(pdfReader.numPages)\n",
    "\n",
    "    # Iterate over each page\n",
    "    for pageNum in range(pdfReader.numPages):\n",
    "        # creating a page object\n",
    "        pageObj = pdfReader.getPage(pageNum)\n",
    "        \n",
    "        # extracting text from page\n",
    "        pageText = pageObj.extractText()\n",
    "        \n",
    "        # extract lines from each page\n",
    "        pageLines = pageText.split(\"\\n\")\n",
    "        \n",
    "        for line in pageLines:\n",
    "            lines.append(line.split(' '))\n",
    "\n",
    "# Pull the columns out and separate columns that were incorrectly joined\n",
    "columns = lines[0]\n",
    "columns[1] = columns[0][5:] + columns[1]\n",
    "columns[0] = columns[0][:5]\n",
    "columns.insert(2, columns[2][:6])\n",
    "columns[3] = columns[3][6:]\n",
    "data = [x for x in lines if x[0].isdigit()]\n",
    "for row in data:\n",
    "    row.insert(1, row[0][2:])\n",
    "    row[0] = row[0][:2]\n",
    "    row.insert(2, row[2][:5])\n",
    "    row[3] = row[3][5:]\n",
    "    \n",
    "senate_census_map = pd.DataFrame(data, columns=columns)\n",
    "senate_census_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35040ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crosstabulate the connections between senate districts and census block groups\n",
    "crosstab = pd.crosstab(senate_census_map[\"Proposed2022_SD\"], senate_census_map[\"BlockGroup\"])\n",
    "# Get a list of census block groups that overlap with each senate district\n",
    "senate_per_bg = crosstab.apply(lambda x : x[x != 0].index.values)\n",
    "senate_per_bg.loc[senate_per_bg.apply(len) != 1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af33945",
   "metadata": {},
   "outputs": [],
   "source": [
    "senate_per_bg2 = crosstab.apply(lambda x : x[x != 0].values)\n",
    "senate_per_bg2.loc[senate_per_bg2.apply(len) != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb605c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scbg = pd.concat([senate_per_bg, senate_per_bg2], axis=1)\n",
    "scbg.loc[(scbg.apply(lambda x : x.apply(len)) != 1).all(axis=1)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8525e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scbg.columns = [\"Senate Districts\", \"Blocks per District\"]\n",
    "scbg.to_csv(\"data/Senate_to_Block_Groups.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed51060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653c33d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0bb42d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec36ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc914ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd1bea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
